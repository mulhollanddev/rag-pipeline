{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import sys\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "import fastembed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe50ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest():\n",
    "    # Get the doc\n",
    "    loader = PyPDFLoader(\"/Users/yehao/Desktop/projetos/wmb/dataset/QuickStatementsBasics.pdf\")\n",
    "    pages = loader.load_and_split()\n",
    "    # Split the pages by char\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1024,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    print(f\"Split {len(pages)} documents into {len(chunks)} chunks.\")\n",
    "    #\n",
    "    embedding = FastEmbedEmbeddings()\n",
    "    #Create vector store\n",
    "    Chroma.from_documents(documents=chunks,  embedding=embedding, persist_directory=\"./sql_chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be5f8ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 16 documents into 36 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yehao/Desktop/projetos/wmb/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# only run this once to generate vector store\n",
    "ingest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "448f4972",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "login() got an unexpected keyword argument 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m access_token_read = \u001b[33m\"\u001b[39m\u001b[33mhf_EZWxAHlTqnvPZWIKyHHzykZYhrlmCZrXQX\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m access_token_write = \u001b[33m\"\u001b[39m\u001b[33mhf_EZWxAHlTqnvPZWIKyHHzykZYhrlmCZrXQX\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess_token_read\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mathe\\OneDrive\\Área de Trabalho\\ProjetoML\\rag-pipeline\\.venv\\Lib\\site-packages\\streamlit\\runtime\\metrics_util.py:443\u001b[39m, in \u001b[36mgather_metrics.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m         _LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[33mFailed to collect command telemetry\u001b[39m\u001b[33m\"\u001b[39m, exc_info=ex)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     result = \u001b[43mnon_optional_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RerunException:\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# Duplicated from below, because static analysis tools get confused\u001b[39;00m\n\u001b[32m    446\u001b[39m     \u001b[38;5;66;03m# by deferring the rethrow.\u001b[39;00m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tracking_activated \u001b[38;5;129;01mand\u001b[39;00m command_telemetry:\n",
      "\u001b[31mTypeError\u001b[39m: login() got an unexpected keyword argument 'token'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#from huggingface_hub import login\n",
    "\n",
    "access_token_read = \"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\"\n",
    "access_token_write = \"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\"\n",
    "login(token = access_token_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7add175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain():\n",
    "    model = ChatOllama(model=\"llama3\")\n",
    "    #\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "            <s> [Instructions] You are an expert assistant in Wikidata tools. \n",
    "            Answer the following question strictly based on the given context, which may contain information about QuickStatements, \n",
    "            SPARQL queries, item creation, property formatting, or submission strategies. \n",
    "            If the context is insufficient to answer, reply with: \"No relevant context available to answer this question.\" [/Instructions] </s> \n",
    "\n",
    "            [Instructions] \n",
    "            Question: {input} \n",
    "            Context: {context} \n",
    "            Answer: \n",
    "            [/Instructions]\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    #Load vector store\n",
    "    embedding = FastEmbedEmbeddings()\n",
    "    vector_store = Chroma(persist_directory=\"./sql_chroma_db\", embedding_function=embedding)\n",
    "\n",
    "    #Create chain\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"score_threshold\": 0.5,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(model, prompt)\n",
    "    chain = create_retrieval_chain(retriever, document_chain)\n",
    "    #\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d431af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str):\n",
    "    #\n",
    "    chain = rag_chain()\n",
    "    # invoke chain\n",
    "    result = chain.invoke({\"input\": query})\n",
    "    # print results\n",
    "    print(result[\"answer\"])\n",
    "    for doc in result[\"context\"]:\n",
    "        print(\"Source: \", doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c55847",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import 'fastembed' Python package. Please install it with `pip install fastembed`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mathe\\OneDrive\\Área de Trabalho\\ProjetoML\\rag-pipeline\\.venv\\Lib\\site-packages\\langchain_community\\embeddings\\fastembed.py:95\u001b[39m, in \u001b[36mFastEmbedEmbeddings.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     fastembed = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfastembed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fastembed'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is quicksatements?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mask\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mask\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     chain = \u001b[43mrag_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# invoke chain\u001b[39;00m\n\u001b[32m      5\u001b[39m     result = chain.invoke({\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: query})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mrag_chain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m prompt = PromptTemplate.from_template(\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m        <s> [Instructions] You are an expert assistant in Wikidata tools. \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#Load vector store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m embedding = \u001b[43mFastEmbedEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m vector_store = Chroma(persist_directory=\u001b[33m\"\u001b[39m\u001b[33m./sql_chroma_db\u001b[39m\u001b[33m\"\u001b[39m, embedding_function=embedding)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#Create chain\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mathe\\OneDrive\\Área de Trabalho\\ProjetoML\\rag-pipeline\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_decorators_v1.py:148\u001b[39m, in \u001b[36mmake_v1_generic_root_validator.<locals>._wrapper1\u001b[39m\u001b[34m(values, _)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper1\u001b[39m(values: RootValidatorValues, _: core_schema.ValidationInfo) -> RootValidatorValues:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mathe\\OneDrive\\Área de Trabalho\\ProjetoML\\rag-pipeline\\.venv\\Lib\\site-packages\\langchain_core\\utils\\pydantic.py:168\u001b[39m, in \u001b[36mpre_init.<locals>.wrapper\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    165\u001b[39m             values[name] = field_info.default\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Call the decorated function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mathe\\OneDrive\\Área de Trabalho\\ProjetoML\\rag-pipeline\\.venv\\Lib\\site-packages\\langchain_community\\embeddings\\fastembed.py:98\u001b[39m, in \u001b[36mFastEmbedEmbeddings.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     95\u001b[39m     fastembed = importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mfastembed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastembed\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg_to_install\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m importlib.metadata.version(pkg_to_install) < MIN_VERSION:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFastEmbedEmbeddings requires \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`pip install -U \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg_to_install\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m`.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    107\u001b[39m     )\n",
      "\u001b[31mImportError\u001b[39m: Could not import 'fastembed' Python package. Please install it with `pip install fastembed`."
     ]
    }
   ],
   "source": [
    "ask(\"What is quicksatements?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
